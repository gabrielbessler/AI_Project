{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from tictactoe import *\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import copy \n",
    "from pprint import pprint\n",
    "from collections import deque\n",
    "from time import time \n",
    "from multiprocessing import Pool \n",
    "\n",
    "import random \n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variants of Tic-Tac-Toe (https://en.wikipedia.org/wiki/Tic-tac-toe_variants)\n",
    "\n",
    "$m,n,k$ game = play on $m$ by $n$ board to try to get $k$ in a row.\n",
    "\n",
    "We have that TicTacToe extends Game, meaning it must have a checkGameOver function. We modify it so that in the initializer it takes in an additional parameter, 'gameOverChecker', a function that takes a board and logger and returns $0$ if nobody won, $1$ if Player one won, or $2$ if Player $2$ won. \n",
    "\n",
    "This allows us to easily implement any variants of the standard 3x3 game that only modify that winning conditions. For example, Misere Tic-tac-toe, or 'inverse' Tic-Tac-Toe, is the game where Player 1 wins if Player 2 gets 3 in a row (we make wrappers for each of the game versions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to support variants of the game where instead of alternating turns, there is some different rule for check whose turn it is. For this, we will add another parameter to TicTacToe constructor, turnChooser. This is passed into the Game superclass. Note that $turnChooser$ is a function that takes in the current player and gives the next player. This lets us support $random$ $turn$ $tic$-$tac$-$toe$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to support larger boards. To do this, we pass in an additional parameter $dimension$. This then creates a board of size $dimension$ by $dimension$. Although this allows us to define boards of arbitrary size, we create $FourByFourTicTacToe$ and $FiveByFiveTicTacToe$. The most logical win condition for an $n$ by $n$ board is $n$ in a row. For this reason we modify the $checkGameOver$ function to take in $n$ - the number of pieces in a row required for a win. Note that other variants are possible - for example, getting a diamond in $4$ by $4$ could also be considered a win. We can then create an $n$ in a row win condition function by using partial functions with $checkGameOver$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we would like to support games in 3 dimensions. We do this by adding yet another paremeter to the initialization - $threeDims$. In order to make it easier to handle 2D vs 3D games, we will always assume the board is 3D - n by n by n, but for 2D we can just get the n by n board by calling board[0]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like easily define combinations of these variants to create custom games. In order to do this, we define a TicTacToeConfig class. Now, TicTacToe simply takes a TicTacToeConfig. This config has all of the default values so we can set any combinations of the ones we want. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Board\n",
    "\n",
    "Looking at the board in the command line is annoying, and we would like some way of seeing what the algorithm is actually doing in a way that is easier to interpret. We will use PyGame to do this. First, we create a `display` method in TicTacToe.\n",
    "\n",
    "The correct way to do this would be to have some event that is triggered when we make a move to update the display. Due to lazyness, we will just spawn a different thread. This then renders the grid 60 times per second and colors it according to the current board state. \n",
    "\n",
    "http://programarcadegames.com/index.php?lang=en&chapter=array_backed_grids\n",
    "https://www.pygame.org/docs/tut/ChimpLineByLine.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning the Value Function with a Neural Network\n",
    "\n",
    "First, we define the neural network. We use tanh to bound the result between -1 and 1 (since this is the bound of our value function). We use standard activation functions, testing first ReLu and then Leaky ReLu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT YET IMPLEMENTED\n",
      "NOT YET IMPLEMENTED\n",
      "NOT YET IMPLEMENTED\n",
      "NOT YET IMPLEMENTED\n",
      "NOT YET IMPLEMENTED\n",
      "NOT YET IMPLEMENTED\n",
      "NOT YET IMPLEMENTED\n",
      "NOT YET IMPLEMENTED\n",
      "NOT YET IMPLEMENTED\n",
      "NOT YET IMPLEMENTED\n",
      "NOT YET IMPLEMENTED\n",
      "NOT YET IMPLEMENTED\n",
      "NOT YET IMPLEMENTED\n",
      "NOT YET IMPLEMENTED\n",
      "[DenseNetRELU(\n",
      "  (first): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (hiddenOne): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (hiddenTwo): Linear(in_features=100, out_features=1, bias=True)\n",
      "), DenseNetLeakyRELU(\n",
      "  (first): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (hiddenOne): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (hiddenTwo): Linear(in_features=100, out_features=1, bias=True)\n",
      "), ConvNet(\n",
      "  (first): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "), ConvNetLeaky(\n",
      "  (first): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "# Regular Feed forward network with only dense layers \n",
    "class DenseNetRELU(nn.Module):\n",
    "    def __init__(self, dimension):\n",
    "        super(DenseNetRELU, self).__init__()\n",
    "        # 9 input features (each of the positions in the board), with a bias\n",
    "        # 1 hidden layer with 9 inputs, 1 output (the value of the state)\n",
    "        numStates = dimension * dimension\n",
    "        self.first = nn.Linear(numStates, numStates, True)\n",
    "        self.hiddenOne = nn.Linear(numStates, numStates, True)\n",
    "        self.hiddenTwo = nn.Linear(numStates, 1, True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.first(x)) \n",
    "        x = F.relu(self.hiddenOne(x)) \n",
    "        x = F.tanh(self.hiddenTwo(x)) \n",
    "        return x\n",
    "    \n",
    "def weights_init_uniform(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        m.weight.data.uniform_(0.0, 1.0)\n",
    "        m.bias.data.fill_(0)\n",
    "    \n",
    "class DenseNetLeakyRELU(nn.Module):\n",
    "    def __init__(self, dimension):\n",
    "        super(DenseNetLeakyRELU, self).__init__()\n",
    "        \n",
    "        numStates = dimension * dimension\n",
    "        self.first = nn.Linear(numStates, numStates, True)\n",
    "        self.hiddenOne = nn.Linear(numStates, numStates, True)\n",
    "        self.hiddenTwo = nn.Linear(numStates, 1, True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.first(x)) \n",
    "        x = F.leaky_relu(self.hiddenOne(x)) \n",
    "        x = F.tanh(self.hiddenTwo(x)) \n",
    "        return x\n",
    "    \n",
    "# Convolutional neural network (for 2D)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, dimension): \n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        \n",
    "        # input is a single channel, we perform 5 convolutions on each entry \n",
    "        # with kernel size of 2 \n",
    "        if dimension == 3:\n",
    "            self.first = nn.Conv2d(1, 5, 2, padding=0) # This gives us a 2x2\n",
    "            self.flattenLayer = nn.Flatten()\n",
    "            self.hidden = nn.Linear(20, 1, True)\n",
    "        else: \n",
    "            print(\"NOT YET IMPLEMENTED\")\n",
    "            self.first = nn.Conv2d(1, 5, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.first(x))\n",
    "        x = self.flattenLayer(x)\n",
    "        x = F.tanh(self.hidden(x)) # Make sure output is between -1 and 1 \n",
    "        return x \n",
    "    \n",
    "class ConvNetLeaky(nn.Module):\n",
    "    def __init__(self, dimension):\n",
    "        super(ConvNetLeaky, self).__init__()\n",
    "        \n",
    "        if dimension == 3:\n",
    "            self.first = nn.Conv2d(1, 5, 2, padding=0) # This gives us a 2x2\n",
    "            self.flattenLayer = nn.Flatten()\n",
    "            self.hidden = nn.Linear(20, 1, True)\n",
    "        else: \n",
    "            print(\"NOT YET IMPLEMENTED\")\n",
    "            self.first = nn.Conv2d(1, 5, 3, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.first(x))\n",
    "        x = self.flattenLayer(x)\n",
    "        x = F.tanh(self.hidden(x)) # Make sure output is between -1 and 1\n",
    "        return x \n",
    "        \n",
    "\n",
    "nets = dict()\n",
    "\n",
    "for dim in range(3, 11): \n",
    "    netOne   = DenseNetRELU(dim)\n",
    "    netTwo   = DenseNetLeakyRELU(dim)\n",
    "    netThree = ConvNet(dim)\n",
    "    netFour  = ConvNetLeaky(dim)\n",
    "    \n",
    "    nets[dim] = [netOne, netTwo, netThree, netFour]\n",
    "\n",
    "print(nets[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define our game tree by defining a node class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    ''' \n",
    "    Node is a single board state in our game tree.\n",
    "    '''\n",
    "    def __init__(self, board): \n",
    "        self.children = []\n",
    "        self.parent = None\n",
    "        self.board = board\n",
    "        self.currTurn = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then make a generic function which will take some starting node and a game constructor (which must create an object that extends the Game abstractclass) and fills out the game tree. It does this more efficiently by using a thread pool. Note that this also returns a list of all the nodes in the tree, which allows us to choose a random node much more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGameTree(game, root, num_nodes): \n",
    "    p = Pool(4)\n",
    "    return findAll(game, root, num_nodes)\n",
    "    \n",
    "def findAll(game, startingNode, num_nodes):\n",
    "    '''\n",
    "    findAll performs BFS from the startingNode. It uses a \n",
    "    '''\n",
    "    visited = [0] * num_nodes\n",
    "    index = 0 \n",
    "\n",
    "    # Initialize a queue with the starting node. \n",
    "    unvisited = deque()\n",
    "    unvisited.append(startingNode)\n",
    "    \n",
    "    # Continue until there are no more unvisited nodes.\n",
    "    while len(unvisited) > 0:\n",
    "        if index % 5000 == 0:\n",
    "            print(index, len(unvisited))\n",
    "        # Store the new visited nodes          \n",
    "        currNode = unvisited.popleft()\n",
    "        visited[index] = currNode\n",
    "        index += 1\n",
    "        \n",
    "        # If game is over, do not add the children\n",
    "        game.board = currNode.board\n",
    "        res = game.checkGameOver()\n",
    "        if res != 0: \n",
    "            continue\n",
    "            \n",
    "        # Find all of the children \n",
    "        for action in game.getAllActions():\n",
    "            child = Node(copy.deepcopy(currNode.board))\n",
    "            child.currTurn = game.turnChooser(currNode.currTurn)\n",
    "            pieceToPlay = 1 if currNode.currTurn == 0 else 2\n",
    "            child.board[action[0]][action[1]][action[2]] = pieceToPlay\n",
    "            child.parent = currNode\n",
    "            \n",
    "            unvisited.append(child)\n",
    "            currNode.children.append(child)\n",
    "    \n",
    "    return visited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate the game tree for all game variants so we have data to train the neural network. Note that for many games the game tree is small enough to store in memory. There are 9 places to place the first piece, then 8 to place the second, etc.., so there are $9! = 362880$ states, many of which are not reachable because someone would win. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "5000 18910\n",
      "10000 32510\n",
      "15000 45990\n",
      "20000 58526\n",
      "25000 67392\n",
      "30000 76372\n",
      "35000 85376\n",
      "40000 94254\n",
      "45000 103240\n",
      "50000 112202\n",
      "55000 121119\n",
      "60000 130090\n",
      "65000 139004\n",
      "70000 147942\n",
      "75000 156896\n",
      "80000 159952\n",
      "85000 162668\n",
      "90000 165360\n",
      "95000 168206\n",
      "100000 170946\n",
      "105000 173480\n",
      "110000 176312\n",
      "115000 179304\n",
      "120000 181878\n",
      "125000 184384\n",
      "130000 187504\n",
      "135000 190046\n",
      "140000 193158\n",
      "145000 195620\n",
      "150000 198312\n",
      "155000 201310\n",
      "160000 204126\n",
      "165000 206434\n",
      "170000 209454\n",
      "175000 212266\n",
      "180000 215102\n",
      "185000 217690\n",
      "190000 220430\n",
      "195000 223132\n",
      "200000 226066\n",
      "205000 228560\n",
      "210000 231324\n",
      "215000 234390\n",
      "220000 237014\n",
      "225000 239398\n",
      "230000 242588\n",
      "235000 243152\n",
      "240000 242330\n",
      "245000 241412\n",
      "250000 240272\n",
      "255000 239326\n",
      "260000 238279\n",
      "265000 237481\n",
      "270000 236437\n",
      "275000 235557\n",
      "280000 234400\n",
      "285000 233445\n",
      "290000 232616\n",
      "295000 231752\n",
      "300000 230555\n",
      "305000 229645\n",
      "310000 228504\n",
      "315000 227830\n",
      "320000 226750\n",
      "325000 225701\n",
      "330000 224936\n",
      "335000 224094\n",
      "340000 222911\n",
      "345000 221937\n",
      "350000 220888\n",
      "355000 220108\n",
      "360000 219059\n",
      "365000 218172\n",
      "370000 217039\n",
      "375000 216055\n",
      "380000 215245\n",
      "385000 214442\n",
      "390000 213203\n",
      "395000 212472\n",
      "400000 211500\n",
      "405000 210313\n",
      "410000 209436\n",
      "415000 208348\n",
      "420000 207544\n",
      "425000 206576\n",
      "430000 205584\n",
      "435000 204432\n",
      "440000 203548\n",
      "445000 202670\n",
      "450000 201842\n",
      "455000 200685\n",
      "460000 199713\n",
      "465000 198570\n",
      "470000 197880\n",
      "475000 197075\n",
      "480000 192346\n",
      "485000 187346\n",
      "490000 182346\n",
      "495000 177346\n",
      "500000 172346\n",
      "505000 167346\n",
      "510000 162346\n",
      "515000 157346\n",
      "520000 152346\n",
      "525000 147346\n",
      "530000 142346\n",
      "535000 137346\n",
      "540000 132346\n",
      "545000 127346\n",
      "550000 122346\n",
      "555000 117346\n",
      "560000 112346\n",
      "565000 107346\n",
      "570000 102346\n",
      "575000 97346\n",
      "580000 92346\n",
      "585000 87346\n",
      "590000 82346\n",
      "595000 77346\n",
      "600000 72346\n",
      "605000 67346\n",
      "610000 62346\n",
      "615000 57346\n",
      "620000 52346\n",
      "625000 47346\n",
      "630000 42346\n",
      "635000 37346\n",
      "640000 32346\n",
      "645000 27346\n",
      "650000 22346\n",
      "655000 17346\n",
      "660000 12346\n",
      "665000 7346\n",
      "670000 2346\n"
     ]
    }
   ],
   "source": [
    "root = Node([[[0,0,0],[0,0,0],[0,0,0]]])\n",
    "NUM_NODES = 1000000\n",
    "game = StandardTicTacToe(None, None, None)\n",
    "\n",
    "vertices = findAll(game, root, NUM_NODES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the data (if we allocated too much space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "for v in range(len(vertices)):\n",
    "    if vertices[v] == 0:\n",
    "        vertices = vertices[0:v]\n",
    "        break \n",
    "        \n",
    "for v in vertices: \n",
    "    v.board_torch = torch.FloatTensor(v.board) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Training Set, Validation Set, and Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537876\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(vertices)\n",
    "\n",
    "training_set_size = int(size*0.8)\n",
    "training_set = vertices[0:training_set_size]\n",
    "\n",
    "test_set_end_index = 0.9size\n",
    "test_set = vertices[training_set_size:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we implement minimax so that we can evaluate a state. We define player 2 winning as -1, and player 1 winning as 1. If currTurn is 0, it's player 1 to move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "memo = dict() # maps each node to a value\n",
    "\n",
    "def minimax(node): \n",
    "    if node in memo: \n",
    "        return memo[node] \n",
    "    \n",
    "    game.board = node.board \n",
    "    res = game.getAllActions()\n",
    "    res2 = game.checkGameOver()\n",
    "    if res2 == 1:\n",
    "        memo[node] = 1\n",
    "        return 1 \n",
    "    elif res2 == 2: \n",
    "        memo[node] = -1 \n",
    "        return -1\n",
    "    elif len(res) == 0: \n",
    "        memo[node] = 0 \n",
    "        return 0\n",
    "        \n",
    "    children = node.children\n",
    "    if node.currTurn == 0: \n",
    "        val = -float('inf')\n",
    "    else: \n",
    "        val = float('inf')\n",
    "        \n",
    "    for child in children: \n",
    "        child_val = minimax(child)\n",
    "        if node.currTurn == 0: \n",
    "            val = max(val, child_val)\n",
    "        else: \n",
    "            val = min(val, child_val)\n",
    "\n",
    "    memo[node] = val\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can train it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## = Training on the GPU = (https://medium.com/dsnet/training-deep-neural-networks-on-a-gpu-with-pytorch-11079d89805)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "device = get_default_device()\n",
    "print(device)\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader(): \n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-1d3346179824>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdimNets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnetIndex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainCount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m11000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdimNets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnetIndex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainCount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m11000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-1d3346179824>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net, trainCount, batchCount, flatten)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0moutputs\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mnodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvertices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\random.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, population, k)\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m21\u001b[0m        \u001b[1;31m# size of a small set minus size of an empty list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "st = time() \n",
    "\n",
    "trainCount = 1000000\n",
    "\n",
    "def train(net, trainCount, batchCount, num_epochs, start_lr, flatten=True):\n",
    "    # Move to GPU if necessary \n",
    "    to_device(net, device)\n",
    "    \n",
    "    start  = start_lr / num_epochs\n",
    "    for lr_var in reverse(arange(start, start_lr + start, start)):\n",
    "    \n",
    "        criterion = nn.MSELoss() # Using mean square error \n",
    "        optimizer = optim.SGD(net.parameters(), lr_var) #  create the optimizer \n",
    "        batchSize = trainCount // batchCount\n",
    "        L2_loss = [0] * trainCount \n",
    "\n",
    "        for batch in range(batchCount):   \n",
    "\n",
    "            # Get training data for one batch \n",
    "            nodes    = [0] * batchSize \n",
    "            expected = [0] * batchSize \n",
    "            outputs  = [0] * batchSize\n",
    "\n",
    "            nodes = random.sample(vertices, batchSize)\n",
    "            for i in range(batchSize): \n",
    "\n",
    "                # Compute the expected result.\n",
    "                if nodes[i] not in memo: \n",
    "                    minimax(nodes[i])\n",
    "                expected[i] = torch.FloatTensor([memo[nodes[i]]])\n",
    "\n",
    "                # Put the board in a format the neural net can use \n",
    "                if flatten:\n",
    "                    nodes[i] = nodes[i].board_torch.reshape(-1)\n",
    "                else:\n",
    "                    nodes[i] = nodes[i].board_torch.reshape(1, 1, 3, 3)      \n",
    "\n",
    "            # Move training data to GPU if necessary \n",
    "            train_dl = DeviceDataLoader(nodes, device) \n",
    "\n",
    "            # Compute the actual and expected results \n",
    "            i = 0\n",
    "            for data in train_dl:\n",
    "                # Print output to user \n",
    "    #             if poo % (batchSize // 2) == 0:\n",
    "    #                 print(f\"Batch {batch}/{batchCount}, {poo}/{batchSize} - {poo/batchSize} - {time() - st}s\", end=\"\\r\")\n",
    "\n",
    "                outputs[i] = net(data)\n",
    "                i += 1\n",
    "\n",
    "    #       Update the neural network\n",
    "            for i in range(batchSize):\n",
    "                optimizer.zero_grad()\n",
    "                out = outputs[i].to(torch.device('cpu'))\n",
    "                loss = criterion(out, expected[i])\n",
    "                loss.backward()\n",
    "                optimizer.step() \n",
    "                L2_loss[i + batch * batchSize] = loss.item()\n",
    "\n",
    "            if batch % 2 == 0:\n",
    "                print(f\"Batch {batch}/{batchCount} - {batchSize} - {time() - st}s - {len(memo.keys())}\", end=\"\\r\")\n",
    "        return L2_loss\n",
    "\n",
    "results = dict() \n",
    "for dim in range(3, 4):\n",
    "    dimNets = nets[dim]\n",
    "    for netIndex in [0, 1, 2, 3]:\n",
    "        if netIndex == 2 or netIndex == 3:\n",
    "            r = train(dimNets[netIndex], trainCount, 11000, False)\n",
    "        else:\n",
    "            r = train(dimNets[netIndex], trainCount, 11000, True)\n",
    "        results[(dim, netIndex)] = r\n",
    "        print(\"\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-709026f4ead8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mCHUNK_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m600\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mdo_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCHUNK_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mdo_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCHUNK_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mdo_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCHUNK_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "def do_plot(L, chunkSize): \n",
    "    L2 = []\n",
    "    for i in range(0, len(L), chunkSize):\n",
    "        if len(L) - i < chunkSize:\n",
    "            amount = len(L) - i\n",
    "        else: \n",
    "            amount = chunkSize \n",
    "        L2.append(sum(L[i:i+chunkSize])/amount)\n",
    "\n",
    "    plt.plot(L2)\n",
    "    plt.show()\n",
    "\n",
    "CHUNK_SIZE = 600\n",
    "do_plot(result[(3,0)], CHUNK_SIZE)\n",
    "do_plot(result[(3,1)], CHUNK_SIZE)\n",
    "do_plot(result[(3,2)], CHUNK_SIZE)\n",
    "do_plot(result[(3,3)], CHUNK_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we pass this network into an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ValueAgent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e2b2015e414c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mnAgent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mValueAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetValueFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ValueAgent' is not defined"
     ]
    }
   ],
   "source": [
    "def netValueFunction(board): \n",
    "    tBoard = torch.FloatTensor(board).reshape(-1)\n",
    "    print(tBoard) \n",
    "    out = net(tBoard)\n",
    "    for i, v in enumerate(out): \n",
    "        if v == out.max():\n",
    "            return i\n",
    "        \n",
    "    return None\n",
    "            \n",
    "nAgent = ValueAgent(0, netValueFunction, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparisons of Greedy Policy to Baseline\n",
    "\n",
    "Here, we compare the greedy policy from the learned value function to an agent that plays random policies and a minimax agent (which plays perfectly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardTicTacToe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-df15822da2e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardTicTacToe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnAgent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDumbAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfoo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StandardTicTacToe' is not defined"
     ]
    }
   ],
   "source": [
    "game = StandardTicTacToe(nAgent, DumbAgent(1), Log(2))\n",
    "\n",
    "results = []\n",
    "for i in range(0, 10): \n",
    "    foo = game.play()\n",
    "    if foo == 0: \n",
    "        print(\"Tie\")\n",
    "        results.append(-1)\n",
    "    else: \n",
    "        results.append(foo)\n",
    "    game.reset()\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
