{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Jupyter Notebook Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%autosave 60\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tictactoe import *\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import copy \n",
    "import json\n",
    "import pickle \n",
    "from collections import deque\n",
    "from time import time \n",
    "from multiprocessing import Pool \n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random \n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    "\n",
    "1. Save both the network and game trees to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variants of Tic-Tac-Toe \n",
    "\n",
    "Many of these variants are listed at https://en.wikipedia.org/wiki/Tic-tac-toe_variants.\n",
    "\n",
    "$m,n,k$ game = play on $m$ by $n$ board to try to get $k$ in a row.\n",
    "\n",
    "We have that TicTacToe extends Game, meaning it must have a checkGameOver function. We modify it so that in the initializer it takes in an additional parameter, 'gameOverChecker', a function that takes a board and logger and returns $0$ if nobody won, $1$ if Player one won, or $2$ if Player $2$ won. \n",
    "\n",
    "This allows us to easily implement any variants of the standard 3x3 game that only modify that winning conditions. For example, Misere Tic-tac-toe, or 'inverse' Tic-Tac-Toe, is the game where Player 1 wins if Player 2 gets 3 in a row (we make wrappers for each of the game versions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to support variants of the game where instead of alternating turns, there is some different rule for check whose turn it is. For this, we will add another parameter to TicTacToe constructor, turnChooser. This is passed into the Game superclass. Note that $turnChooser$ is a function that takes in the current player and gives the next player. This lets us support $random$ $turn$ $tic$-$tac$-$toe$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to support larger boards. To do this, we pass in an additional parameter $dimension$. This then creates a board of size $dimension$ by $dimension$. Although this allows us to define boards of arbitrary size, we create $FourByFourTicTacToe$ and $FiveByFiveTicTacToe$. The most logical win condition for an $n$ by $n$ board is $n$ in a row. For this reason we modify the $checkGameOver$ function to take in $n$ - the number of pieces in a row required for a win. Note that other variants are possible - for example, getting a diamond in $4$ by $4$ could also be considered a win. We can then create an $n$ in a row win condition function by using partial functions with $checkGameOver$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we would like to support games in 3 dimensions. We do this by adding yet another paremeter to the initialization - $threeDims$. In order to make it easier to handle 2D vs 3D games, we will always assume the board is 3D - n by n by n, but for 2D we can just get the n by n board by calling board[0]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like easily define combinations of these variants to create custom games. In order to do this, we define a TicTacToeConfig class. Now, TicTacToe simply takes a TicTacToeConfig. This config has all of the default values so we can set any combinations of the ones we want. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Board\n",
    "\n",
    "Looking at the board in the command line is annoying, and we would like some way of seeing what the algorithm is actually doing in a way that is easier to interpret. We will use PyGame to do this. First, we create a `display` method in TicTacToe.\n",
    "\n",
    "The correct way to do this would be to have some event that is triggered when we make a move to update the display. Due to lazyness, we will just spawn a different thread. This then renders the grid 60 times per second and colors it according to the current board state. \n",
    "\n",
    "http://programarcadegames.com/index.php?lang=en&chapter=array_backed_grids\n",
    "https://www.pygame.org/docs/tut/ChimpLineByLine.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the Value Function with a Neural Network\n",
    "\n",
    "First, we define the neural network. We use tanh to bound the result between -1 and 1 (since this is the bound of our value function). We use standard activation functions, testing first ReLu and then Leaky ReLu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular Feed forward network with only dense layers \n",
    "class DenseNetRELU(nn.Module):\n",
    "    def __init__(self, dimension):\n",
    "        super(DenseNetRELU, self).__init__()\n",
    "        # 9 input features (each of the positions in the board), with a bias\n",
    "        # 1 hidden layer with 9 inputs, 1 output (the value of the state)\n",
    "        numStates = dimension * dimension\n",
    "        self.first = nn.Linear(numStates, numStates, True)\n",
    "        self.hiddenOne = nn.Linear(numStates, numStates, True)\n",
    "        self.hiddenTwo = nn.Linear(numStates, 1, True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.first(x)) \n",
    "        x = F.relu(self.hiddenOne(x)) \n",
    "        x = torch.tanh(self.hiddenTwo(x)) \n",
    "        return x\n",
    "    \n",
    "    def evaluate(self, board): \n",
    "        return self(torch.FloatTensor(board).reshape(-1))\n",
    "    \n",
    "class DenseNetLeakyRELU(nn.Module):\n",
    "    def __init__(self, dimension):\n",
    "        super(DenseNetLeakyRELU, self).__init__()\n",
    "        \n",
    "        numStates = dimension * dimension\n",
    "        self.first = nn.Linear(numStates, numStates, True)\n",
    "        self.hiddenOne = nn.Linear(numStates, numStates, True)\n",
    "        self.hiddenTwo = nn.Linear(numStates, 1, True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.first(x)) \n",
    "        x = F.leaky_relu(self.hiddenOne(x)) \n",
    "        x = torch.tanh(self.hiddenTwo(x)) \n",
    "        return x\n",
    "    \n",
    "    def evaluate(self, board): \n",
    "        return self(torch.FloatTensor(board).reshape(-1))\n",
    "    \n",
    "# Convolutional neural network (for 2D)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, dimension): \n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # input is a single channel, we perform 5 convolutions on each entry \n",
    "        # with kernel size of 2 \n",
    "        if dimension == 3:\n",
    "            # 1 in_channel, \n",
    "            # 5 out_channels\n",
    "            self.first = nn.Conv2d(1, 5, kernel_size=2, padding=0) # This gives us 5 2x2 squares\n",
    "            self.flattenLayer = nn.Flatten()\n",
    "            self.hidden = nn.Linear(20, 1, True)\n",
    "        else: \n",
    "            # TODO \n",
    "            self.first = nn.Conv2d(1, 5, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.first(x))\n",
    "        x = self.flattenLayer(x)\n",
    "        x = torch.tanh(self.hidden(x)) # Make sure output is between -1 and 1 \n",
    "        return x \n",
    "    \n",
    "    def evaluate(self, board):\n",
    "        return self(torch.FloatTensor(board).reshape(1, 1, 3, 3))\n",
    "    \n",
    "class ConvNetLeaky(nn.Module):\n",
    "    def __init__(self, dimension):\n",
    "        super(ConvNetLeaky, self).__init__()\n",
    "        \n",
    "        if dimension == 3:\n",
    "            self.first = nn.Conv2d(1, 5, 2, padding=0) # This gives us a 2x2\n",
    "            self.flattenLayer = nn.Flatten()\n",
    "            self.hidden = nn.Linear(20, 1, True)\n",
    "        else:\n",
    "            # TODO\n",
    "            self.first = nn.Conv2d(1, 5, 3, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.first(x))\n",
    "        x = self.flattenLayer(x)\n",
    "        x = torch.tanh(self.hidden(x)) # Make sure output is between -1 and 1\n",
    "        return x \n",
    "        \n",
    "    def evaluate(self, board):\n",
    "        return self(torch.FloatTensor(board).reshape(1, 1, 3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we initialize all of the neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = dict()\n",
    "for dim in range(3, 5): \n",
    "    netOne   = DenseNetRELU(dim)\n",
    "    netTwo   = DenseNetLeakyRELU(dim)\n",
    "    netThree = ConvNet(dim)\n",
    "    netFour  = ConvNetLeaky(dim)\n",
    "    \n",
    "    nets[dim] = [netOne, netTwo, netThree, netFour]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the most successful neural network and turn it into the network we use for MCTS by adding the policy head. Instead of having a single value output, we output the entire probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTSNet(nn.Module):\n",
    "    def __init__(self, dimension):\n",
    "        super(MCTSNet, self).__init__()\n",
    "        \n",
    "        numStates = dimension * dimension\n",
    "        self.first = nn.Linear(numStates, numStates, True)\n",
    "        self.hiddenOne = nn.Linear(numStates, numStates, True)\n",
    "        self.valueHead = nn.Linear(numStates, 1, True)          # Give us a value for the board\n",
    "        self.policyHead = nn.Linear(numStates, numStates, True) # Give us a probability for each action\n",
    "        \n",
    "        # Maybe do this in an outside loop?\n",
    "        LEARNING_RATE = 0.05\n",
    "        self.criterionVal = nn.MSELoss()\n",
    "        self.criterionPol = nn.MSELoss()\n",
    "        self.optimizer = optim.SGD(self.parameters(), lr=LEARNING_RATE)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.first(x)) \n",
    "        x = F.leaky_relu(self.hiddenOne(x)) \n",
    "        value = torch.tanh(self.valueHead(x)) \n",
    "        policy = torch.sigmoid(self.policyHead(x)) # Probabilities must be between 0 and 1\n",
    "#         policy /= policy.sum()                # Normalize so that they add up to 1 \n",
    "#         return torch.cat((value, policy))\n",
    "        return value, policy\n",
    "    \n",
    "    def predict(self, board): \n",
    "        return self(torch.FloatTensor(board).reshape(-1))\n",
    "    \n",
    "    def update(self, state, value, probabilities):\n",
    "        # https://discuss.pytorch.org/t/a-model-with-multiple-outputs/10440\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        predictedVal, predictedPol    = self.predict(state)\n",
    "        actualVal,    actualPol       = torch.FloatTensor([value]), torch.FloatTensor(probabilities)\n",
    "        lossVal = self.criterionVal(actualVal, predictedVal)\n",
    "        lossPol = self.criterionPol(actualPol, predictedPol) \n",
    "        loss = lossVal + lossPol\n",
    "        \n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = MCTSNet(3)\n",
    "n.update(torch.FloatTensor([0]*9), 0, [0, 0, 0, 0, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define our game tree by defining a node class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    ''' \n",
    "    Node is a single board state in our game tree.\n",
    "    '''\n",
    "    def __init__(self, board): \n",
    "        self.children = []\n",
    "#         self.parent = None\n",
    "        self.board = board \n",
    "        self.currPlayer = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then make a generic function which will take some starting node and a game constructor (which must create an object that extends the Game abstractclass) and fills out the game tree. It does this more efficiently by using a thread pool. Note that this also returns a list of all the nodes in the tree, which allows us to choose a random node much more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boardToTuple(board):\n",
    "    return tuple([tuple([tuple(j) for j in l]) for l in board])\n",
    "\n",
    "def boardToList(board):\n",
    "    return [list([list(j) for j in l]) for l in board]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0, 0, 0], [0, 0, 0], [0, 0, 0]]]\n"
     ]
    }
   ],
   "source": [
    "n = Node(boardToTuple([[[0,0,0],[0,0,0],[0,0,0]]]))\n",
    "a = boardToList(n.board)\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAllGraphSearch(game, startingNode, num_nodes): \n",
    "    '''\n",
    "    findAllGraphSearch performs BFS from the startingNode but will not expand the same node twice. \n",
    "    '''\n",
    "    count = 0 \n",
    "    with tqdm(total = num_nodes) as pbar: \n",
    "        visited = dict()\n",
    "        \n",
    "        # Initialize a queue with the starting node. \n",
    "        unvisited = deque()\n",
    "        unvisited.append(startingNode) \n",
    "        visited[startingNode.board] = startingNode\n",
    "        \n",
    "        # Continue until there are no more unvisited nodes. \n",
    "        while len(unvisited) > 0:\n",
    "            count += 1\n",
    "            pbar.update() \n",
    "            \n",
    "            currNode = unvisited.popleft()\n",
    "            \n",
    "            # Check if the current game is over. If it is, skip this node\n",
    "            # This does not check if the game ends in a draw.\n",
    "            game.board = currNode.board\n",
    "            if game.checkGameOver() != 0: \n",
    "                continue\n",
    "                \n",
    "            # Find all of the children of the current node we are looking at\n",
    "            pieceToPlay = 1 if currNode.currPlayer == 0 else 2\n",
    "            allActions = game.getAllActions()\n",
    "            currNode.children = [0] * len(allActions)\n",
    "            for actionIndex, action in enumerate(allActions):\n",
    "                # Create the child node\n",
    "                child = Node(boardToList(currNode.board))\n",
    "                child.currPlayer = game.turnChooser(currNode.currPlayer)\n",
    "                child.board[action[0]][action[1]][action[2]] = pieceToPlay\n",
    "                \n",
    "                # Convert to hashable\n",
    "                child.board = boardToTuple(child.board)\n",
    "                \n",
    "                # Check if we have already queued the same node to be visited\n",
    "                if child.board not in visited: \n",
    "                    visited[child.board] = child     # Save the fact that we will look at this node later.  \n",
    "                    unvisited.append(child)          # Look at this child node in some later iteration\n",
    "                \n",
    "                # Add this child node as a child of the current node\n",
    "                currNode.children[actionIndex] = visited[child.board] \n",
    "        \n",
    "        pbar.update(num_nodes - count)\n",
    "        return visited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate the game tree for all game variants so we have data to train the neural network. Note that for many games the game tree is small enough to store in memory. There are 9 places to place the first piece, then 8 to place the second, etc.., so there are $9! = 362880$ states, many of which are not reachable because someone would win. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the data (if we allocated too much space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanUpData(vertices):\n",
    "    with tqdm(total = len(vertices), desc=\"Removing Unused Allocated Space\") as pbar: \n",
    "        for v in range(len(vertices)):\n",
    "            pbar.update() \n",
    "            if vertices[v] == 0:\n",
    "                pbar.update(len(vertices) - v - 1) \n",
    "                vertices = vertices[0:v]\n",
    "                break \n",
    "\n",
    "    for v in tqdm(vertices, desc=\"Converting to Tensors\"): \n",
    "        v.board_torch = torch.FloatTensor(v.board) \n",
    "        \n",
    "    return vertices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Training Set, Validation Set, and Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataFromGraph(vertices): \n",
    "    keys = list(vertices.keys())\n",
    "    \n",
    "    random.shuffle(keys)\n",
    "\n",
    "    size = len(keys)\n",
    "    training_set_size = int(size*0.8)\n",
    "    training_set = keys[0:training_set_size]\n",
    "\n",
    "    test_set_end_index = int(0.9 * size)\n",
    "    test_set = keys[training_set_size:test_set_end_index]\n",
    "\n",
    "    validation_set = keys[test_set_end_index:]\n",
    "\n",
    "    return test_set, training_set, validation_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we implement minimax so that we can evaluate a state. We define player 2 winning as -1, and player 1 winning as 1. If currPlayer is 0, it's player 1 to move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "memo = dict()\n",
    "def minimax(game, vertex, maxDepth = None, neuralNet = None): \n",
    "    \n",
    "    # Check if we already have the value for this vertex. \n",
    "    if vertex in memo and maxDepth is None: \n",
    "        return memo[vertex] \n",
    "    \n",
    "    game.board = vertex.board \n",
    "    res = game.getAllActions()\n",
    "    res2 = game.checkGameOver()\n",
    "    if res2 == 1:\n",
    "        memo[vertex] = 1\n",
    "        return 1 \n",
    "    elif res2 == 2: \n",
    "        memo[vertex] = -1 \n",
    "        return -1\n",
    "    elif len(res) == 0: \n",
    "        memo[vertex] = 0 \n",
    "        return 0\n",
    "    \n",
    "    # If we are not a terminal state but the maxDepth is 0, just return 0, or use the value heuristic. \n",
    "    if maxDepth == 0: \n",
    "        if neuralNet is None: \n",
    "            return 0\n",
    "    \n",
    "        return net.evaluate(game.board)\n",
    "    if maxDepth is not None: \n",
    "        maxDepth -= 1 \n",
    "    \n",
    "    children = vertex.children\n",
    "    if vertex.currPlayer == 0: \n",
    "        val = -float('inf')\n",
    "    else: \n",
    "        val = float('inf')\n",
    "    \n",
    "    \n",
    "    for child in children: \n",
    "        child_val = minimax(game, child)\n",
    "        if vertex.currPlayer == 0: \n",
    "            val = max(val, child_val)\n",
    "        else: \n",
    "            val = min(val, child_val)\n",
    "\n",
    "    # Once we have computed the value for this vertex, save it. \n",
    "    memo[vertex] = val\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can train it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on the GPU\n",
    "\n",
    "A large part of this information comes from https://medium.com/dsnet/training-deep-neural-networks-on-a-gpu-with-pytorch-11079d89805."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "device = get_default_device()\n",
    "device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExpectedResults(data, game, batchSize, flatten): \n",
    "    expected = [0] * batchSize\n",
    "    nodes = random.sample(data, batchSize) \n",
    "    for i in range(batchSize): \n",
    "        if nodes[i] not in memo: \n",
    "            minimax(game, nodes[i])\n",
    "        expected[i] = torch.FloatTensor([memo[nodes[i]]])\n",
    "        \n",
    "        # Put the board in a format the neural net can use \n",
    "        if flatten:\n",
    "            nodes[i] = nodes[i].board_torch.reshape(-1)\n",
    "        else:\n",
    "            nodes[i] = nodes[i].board_torch.reshape(1, 3, 3)\n",
    "            \n",
    "    return nodes, expected \n",
    "        \n",
    "def train(data, game, net, trainCount, batchCount, num_epochs, start_lr, lrStepFactor, flatten=True):\n",
    "    # Move to GPU if necessary \n",
    "    net.to(device)\n",
    "    \n",
    "    lr_step = (start_lr / num_epochs) / lrStepFactor\n",
    "    \n",
    "    epoch = 0 \n",
    "    learning_rates = np.arange(start_lr, start_lr - num_epochs * lr_step, -lr_step)\n",
    "    losses = []\n",
    "    criterion = nn.MSELoss() # Using mean square error \n",
    "    batchSize = trainCount // batchCount\n",
    "    \n",
    "    for lr_var in tqdm(learning_rates, desc=f\"Neural Net Training\"):\n",
    "        epoch += 1\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr_var) #  create the optimizer  \n",
    "        L = [0] * batchCount \n",
    "        \n",
    "        allNodes = []\n",
    "        allExpected = []\n",
    "        for batch in range(batchCount): \n",
    "            nodes, expected = getExpectedResults(data, game, batchSize, flatten)\n",
    "            allNodes.append(torch.stack(nodes).to(device))\n",
    "            allExpected.append(expected)\n",
    "        \n",
    "        for batch in range(batchCount):\n",
    "            # Get training data for one batch \n",
    "            outputs  = [0] * batchSize\n",
    "            nodes, expected = allNodes[batch], allExpected[batch] \n",
    "            \n",
    "            # Move training data to GPU if necessary \n",
    "            outputs = net(nodes) \n",
    "\n",
    "            # Update the neural network\n",
    "            optimizer.zero_grad()\n",
    "            expected = torch.stack(expected)\n",
    "            expected = expected.to(device)\n",
    "            loss = criterion(outputs, expected) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            L[batch] = loss.item()\n",
    "                \n",
    "        losses.append(L)\n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments (Results)\n",
    "\n",
    "First, we begin with the simplests case - 3x3. We determined empirically that training the first neural network with the parameters listed below would be sufficient to reach minimal loss. Then, we use these parameters to train the 4 different network topologies. After testing it seems that ```findAll``` is _slightly_ faster than ```findAllGraphSearch```, however, there are 2 benefits to using ```findAllGraphSearch```. \n",
    "\n",
    "1. It outputs a hashmap mapping board states to nodes. Although this does not currently give us a speed increase, we expect that this would enable speed increases in the training loop (e.g. by allowing us to use data loaders). \n",
    "\n",
    "\n",
    "2. It looks at significantly fewer nodes, which makes it faster overall. Further, since there is less duplicate data, it uses less memory to store all of the nodes. While the ```findAll``` looks at 986410 nodes, ```findAllGraphSearch``` looks at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "memo = dict()\n",
    "def getGameTree(game, dim): \n",
    "    root = Node([[[0] * dim for _ in range(dim)]])\n",
    "    root.board = boardToTuple(root.board)\n",
    "    NUM_NODES = 3**(dim**2)\n",
    "    if dim == 4: \n",
    "        NUM_NODES = 9810255\n",
    "    \n",
    "    vertices = findAllGraphSearch(game, root, NUM_NODES) \n",
    "    test_set, training_set, validation_set = splitDataFromGraph(vertices)\n",
    "    return test_set, training_set, validation_set, vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1182e4c0e92c48a6a368ba6fb38060e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=19683), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a6303ca291447a8fff5ab5166baa60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting to Tensors', max=4496, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d572fed6a9a642d582ab00cbea6dca62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting to Tensors', max=562, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede275fdc2be4cd598169484deab8caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting to Tensors', max=562, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gameOverCheck = partial(checkGameOver, n=3)\n",
    "config = TicTacToeConfig(turnChooser=defaultTurnChooser, gameOverChecker=gameOverCheck, dimension=dim, threeDims=False)\n",
    "game = TicTacToe(None, None, None, config)\n",
    "    \n",
    "test_set_one, training_set_one, validation_set_one, vertices = getGameTree(game, 3)\n",
    "\n",
    "# For now, don't take advantage of the hashtable (this is only needed for graph search)\n",
    "training_set_one = [vertices[i] for i in training_set_one]\n",
    "for v in tqdm(training_set_one, desc=\"Converting to Tensors\"): \n",
    "    v.board_torch = torch.FloatTensor(v.board) \n",
    "\n",
    "validation_set_one = [vertices[i] for i in validation_set_one]\n",
    "for v in tqdm(validation_set_one, desc=\"Converting to Tensors\"): \n",
    "    v.board_torch = torch.FloatTensor(v.board)\n",
    "    \n",
    "test_set_one = [vertices[i] for i in test_set_one]\n",
    "for v in tqdm(test_set_one, desc=\"Converting to Tensors\"): \n",
    "    v.board_torch = torch.FloatTensor(v.board)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4496 562 562\n",
      "5620\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(training_set_one)} {len(validation_set_one)} {len(test_set_one)}\")\n",
    "print(len(training_set_one) + len(validation_set_one) + len(test_set_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ae53f1a0334c2dae7dff1fad9304e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Neural Net Training', max=2, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3e9fd04ebb4144a59f227628a7e4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Neural Net Training', max=2, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c99200c56147ffb258f29b2cc74283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Neural Net Training', max=2, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59fc87258bf2424abcf7c91e315d06ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Neural Net Training', max=2, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainCount = len(training_set_one)\n",
    "batchSize = 32\n",
    "batchCount = trainCount // batchSize \n",
    "startLR = 0.04\n",
    "numEpochs = 2\n",
    "lrStepFactor = 1.5 \n",
    "\n",
    "results = dict() \n",
    "for netIndex in range(4):\n",
    "    results[(3, netIndex)] = train(training_set_one, game, nets[3][netIndex],\n",
    "                                   trainCount, batchCount, numEpochs,\n",
    "                                   startLR, lrStepFactor, (netIndex == 0 or netIndex == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try training it for a 4x4 board (using the exact same neural network and same parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808d6046ef0f464fa0075a98f9e97500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9810255), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-456d9ed8ea34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTicTacToeConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mturnChooser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefaultTurnChooser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgameOverChecker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgameOverCheck\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreeDims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTicTacToe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvertices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetGameTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# Approximately 8500 iterations per second\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-e336f303bf5c>\u001b[0m in \u001b[0;36mgetGameTree\u001b[1;34m(game, dim)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mNUM_NODES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m9810255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mvertices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfindAllGraphSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_NODES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitDataFromGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvertices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvertices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-96-abbdc564e267>\u001b[0m in \u001b[0;36mfindAllGraphSearch\u001b[1;34m(game, startingNode, num_nodes)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;31m# This does not check if the game ends in a draw.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckGameOver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\AI_Project\\tictactoe.py\u001b[0m in \u001b[0;36mcheckGameOver\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheckGameOver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgameOverChecker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mValueAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAgent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\AI_Project\\tictactoe.py\u001b[0m in \u001b[0;36mcheckGameOver\u001b[1;34m(board, logger, n)\u001b[0m\n\u001b[0;32m     49\u001b[0m                         \u001b[0mdepth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                     \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misValid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mboard\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                         \u001b[0mdiagOne\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gameOverCheck = partial(checkGameOver, n=4)\n",
    "config = TicTacToeConfig(turnChooser=defaultTurnChooser, gameOverChecker=gameOverCheck, dimension=4, threeDims=False)\n",
    "game = TicTacToe(None, None, None, config)\n",
    "test_set, training_set, validation_set, vertices = getGameTree(game, 4)\n",
    "# Approximately 8500 iterations per second "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bdd348255cb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{len(training_set)} {len(validation_set)} {len(test_set)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_set\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_set' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"{len(training_set)} {len(validation_set)} {len(test_set)}\")\n",
    "print(len(training_set) + len(validation_set) + len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to the correct format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = [vertices[i] for i in training_set]\n",
    "for v in tqdm(training_set, desc=\"Converting to Tensors\"): \n",
    "    v.board_torch = torch.FloatTensor(v.board) \n",
    "\n",
    "validation_set = [vertices[i] for i in validation_set]\n",
    "for v in tqdm(validation_set, desc=\"Converting to Tensors\"): \n",
    "    v.board_torch = torch.FloatTensor(v.board)\n",
    "    \n",
    "test_set = [vertices[i] for i in test_set]\n",
    "for v in tqdm(test_set, desc=\"Converting to Tensors\"): \n",
    "    v.board_torch = torch.FloatTensor(v.board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data out to an external file, using Pickle as this lets us save external objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"training_set_4by4.pkl\",\"wb\")\n",
    "pickle.dump(training_set, f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"validation_set_4by4.pkl\", \"wb\")\n",
    "pickle.dump(validation_set, f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"test_set_4by4.pkl\", \"wb\")\n",
    "pickle.dump(test_set, f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"vertices_4by4.pkl\", \"wb\") \n",
    "pickle.dump(vertices, f) \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data already exists in the external file, we can load directly from the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandler = open(\"training_set_4by4.pkl\", 'r') \n",
    "training_set = pickle.load(filehandler)\n",
    "\n",
    "filehandler = open(\"validation_set_4by4.pkl\", 'r')\n",
    "validation_set = pickle.load(filehandler)\n",
    "\n",
    "filehandler = open(\"test_set_4by4.pkl\", 'r')\n",
    "test_set = pickle.load(filehandler)\n",
    "\n",
    "filehandler = open(\"vertices_4by4.pkl\", 'r')\n",
    "vertices = pickle.load(filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model for the 4x4 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95137bd600ec4bc19a113f0b4f2b5627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Neural Net Training', max=5, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'board'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-0d3e924ab3ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnetIndex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     results[(4, netIndex)] = train(training_set, game, nets[4][netIndex], trainCount, batchCount, numEpochs, startLR,\n\u001b[1;32m---> 10\u001b[1;33m                                    lrStepFactor, (netIndex == 0 or netIndex == 1))\n\u001b[0m",
      "\u001b[1;32m<ipython-input-45-21efe63b4d36>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(data, game, net, trainCount, batchCount, num_epochs, start_lr, lrStepFactor, flatten)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mallExpected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatchCount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mnodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetExpectedResults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0mallNodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mallExpected\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpected\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-21efe63b4d36>\u001b[0m in \u001b[0;36mgetExpectedResults\u001b[1;34m(data, game, batchSize, flatten)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mminimax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mexpected\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-2e9e5b968033>\u001b[0m in \u001b[0;36mminimax\u001b[1;34m(game, vertex, maxDepth)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvertex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvertex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetAllActions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mres2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckGameOver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'board'"
     ]
    }
   ],
   "source": [
    "trainCount = 1000\n",
    "batchSize = 32\n",
    "batchCount = trainCount // batchSize \n",
    "startLR = 0.04\n",
    "numEpochs = 5\n",
    "lrStepFactor = 1.5 \n",
    "\n",
    "for netIndex in range(4):\n",
    "    results[(4, netIndex)] = train(training_set, game, nets[4][netIndex], trainCount, batchCount, numEpochs, startLR,\n",
    "                                   lrStepFactor, (netIndex == 0 or netIndex == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try training it for a 5x5 board (using the exact same neural networks and same parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameOverCheck = partial(checkGameOver, n=5)\n",
    "config = TicTacToeConfig(turnChooser=defaultTurnChooser, gameOverChecker=gameOverCheck, dimension=7, threeDims=False)\n",
    "game = TicTacToe(None, None, None, config)\n",
    "vertices = getGameTree(game, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this tree is way too large to even store in memory and create. Finding the minimax values for nodes in the tree would also be extremely slow, even if we had the entire tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Results\n",
    "\n",
    "First, we plot the loss as the network is being trained: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_plot(L, chunkSize, showEpochs = True): \n",
    "    L2 = []\n",
    "    epoch_index = 0 \n",
    "    for epoch in L:\n",
    "        if showEpochs: \n",
    "            plt.axvline(x=len(L2), color=\"r\", linestyle='dashed')\n",
    "        for i in range(0, len(epoch), chunkSize):\n",
    "            if len(epoch) - i < chunkSize:\n",
    "                amount = len(epoch) - i\n",
    "            else: \n",
    "                amount = chunkSize playGames(agentsPlayerOne, True, \"value-minimax\")\n",
    " \n",
    "            L2.append(sum(epoch[i:i+amount])/amount)\n",
    "        \n",
    "    plt.plot(L2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "(4, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-c44e41eca545>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mCHUNK_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdo_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCHUNK_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mdo_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCHUNK_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdo_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCHUNK_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (4, 0)"
     ]
    }
   ],
   "source": [
    "CHUNK_SIZE = 200\n",
    "for i in [3, 4]:\n",
    "    do_plot(results[(i,0)], CHUNK_SIZE, False)\n",
    "    do_plot(results[(i,1)], CHUNK_SIZE, False)\n",
    "    do_plot(results[(i,2)], CHUNK_SIZE, False)\n",
    "    do_plot(results[(i,3)], CHUNK_SIZE, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the accuracy and loss against the validation set. The loss is computed as we normally do - by taking the value given by the network and comparing it to the value given by the minimax algorithm. The accuracy is a measure of what percentage of the time we make the optimal move. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8428571428571429\n",
      "Accuracy: 0.8428571428571429\n",
      "Accuracy: 0.8469387755102041\n",
      "Accuracy: 0.8551020408163266\n",
      "Loss: 0.47284767031669617\n",
      "Loss: 0.47166720032691956\n",
      "Loss: 0.4702538251876831\n",
      "Loss: 0.47134023904800415\n"
     ]
    }
   ],
   "source": [
    "dimNets = nets[3]\n",
    "loss = [0, 0, 0, 0]     # One loss per net\n",
    "accuracy = [0, 0, 0, 0] # One accuracy count per neural net \n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for netIndex in [0, 1, 2, 3]:\n",
    "    net = dimNets[netIndex]\n",
    "    flatten = (netIndex == 0 or netIndex == 1)\n",
    "    correctMoves = 0 \n",
    "    wrongMoves = 0 \n",
    "    \n",
    "    for node in validation_set_one:\n",
    "        res = net.evaluate(node.board)\n",
    "            \n",
    "        # For each node, look at all of the possible actions we can take\n",
    "        game.board = boardToList(node.board) \n",
    "        game.currPlayer = node.currPlayer\n",
    "        actions = game.getAllActions()\n",
    "        gameStatus = game.checkGameOver() \n",
    "        \n",
    "        # Evaluate the state of the current board\n",
    "        originalBoard = copy.deepcopy(game.board)\n",
    "        v = minimax(game, vertices[boardToTuple(game.board)])\n",
    "        expected = torch.FloatTensor([v])\n",
    "        loss[netIndex] += criterion(torch.FloatTensor([res[0].item()]), expected)\n",
    "        game.board = originalBoard\n",
    "         \n",
    "        if game.checkGameOver() != 0: \n",
    "            continue \n",
    "        \n",
    "        # Pick the action according to the greedy policy \n",
    "        maxValue = None\n",
    "        maxIndex = None \n",
    "        \n",
    "        maxValueMinimax = None\n",
    "        maxIndecesMinimax = []\n",
    "        \n",
    "        for i in range(len(actions)):\n",
    "            originalBoard = copy.deepcopy(game.board)\n",
    "            game.makeMove(actions[i])\n",
    "            \n",
    "            # Evaluate how good the board is according to the neural network\n",
    "            value = net.evaluate(game.board)[0].item()\n",
    "                \n",
    "            # See if it's better than the best move we've seen so far \n",
    "            if maxIndex is None or (game.currPlayer == 1 and value > maxValue) or (game.currPlayer == 2 and value < maxValue): \n",
    "                maxValue = value \n",
    "                maxIndex = i\n",
    "                \n",
    "            # Evaluate how good the board is according to minimax. \n",
    "            node = vertices[boardToTuple(game.board)]\n",
    "            minimiMaxValue = minimax(game, node) \n",
    "            # We have to chose SOME action\n",
    "            # If player 1, then we are trying to maximize value. If player 2, we are trying to minimize. \n",
    "            if (maxIndecesMinimax == []) or (game.currPlayer == 1 and minimiMaxValue > maxValueMinimax) or (game.currPlayer == 2 and minimiMaxValue > maxValueMinimax): \n",
    "                maxIndecesMinimax = [i] \n",
    "                maxValueMinimax = minimiMaxValue\n",
    "            elif minimiMaxValue == maxValueMinimax:\n",
    "                maxIndecesMinimax.append(i)\n",
    "            \n",
    "            # Reset the board back to initial state \n",
    "            game.board = originalBoard\n",
    "            \n",
    "        # Compare the greedy policy to the actual optimal policy (according to minimax) \n",
    "        if maxIndex in maxIndecesMinimax: \n",
    "            correctMoves += 1 \n",
    "        else: \n",
    "            wrongMoves += 1\n",
    "    \n",
    "    totalMoves = correctMoves + wrongMoves\n",
    "    accuracy[netIndex] = correctMoves / totalMoves\n",
    "\n",
    "for val in accuracy:\n",
    "    print(f\"Accuracy: {val}\")\n",
    "    \n",
    "for l in loss: \n",
    "    print(f\"Loss: {l / len(validation_set_one)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we pass this network into an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a neural network, return a value function we can use for an agent. \n",
    "def netValueFunction(neuralNet, flatten): \n",
    "    # This should return an action\n",
    "    def valueFunction(board, game):     \n",
    "        actions = game.getAllActions() \n",
    "        \n",
    "        currAction = None \n",
    "        currVal = float('inf')\n",
    "        if game.currPlayer == 0:  # If first player, want to maximize the value.\n",
    "            currVal = -float('inf')\n",
    "            \n",
    "        for action in actions: \n",
    "            origBoard = copy.deepcopy(game.board)\n",
    "            origTurn = game.currTurn\n",
    "            \n",
    "            game.makeMove(action) \n",
    "            value = neuralNet.evaluate(game.board).item() \n",
    "            \n",
    "            if (game.currPlayer == 0 and value > currVal) or (game.currPlayer == 1 and value < currVal): \n",
    "                currVal = value \n",
    "                currAction = action \n",
    "            \n",
    "            game.board = origBoard\n",
    "            game.currTurn = origTurn\n",
    "            \n",
    "        return currAction \n",
    "    \n",
    "    return valueFunction\n",
    "\n",
    "def getMinimaxValueFunction(depth = None):\n",
    "    \n",
    "    def minimaxValueFunction(board, game, net = None):\n",
    "        actions = game.getAllActions() \n",
    "        currAction = None \n",
    "        if game.currPlayer == 0:  # If first player, want to maximize the value \n",
    "            currVal = -float('inf')\n",
    "        elif game.currPlayer == 1: # If the second player, want to minimize the value \n",
    "            currVal = float('inf')\n",
    "\n",
    "        for action in actions: \n",
    "            origBoard = copy.deepcopy(game.board)\n",
    "            origTurn = game.currTurn\n",
    "\n",
    "            game.makeMove(action) \n",
    "            value = minimax(game, vertices[boardToTuple(game.board)], depth, net)\n",
    "\n",
    "            if (game.currPlayer == 0 and value > currVal) or (game.currPlayer == 1 and value < currVal): \n",
    "                currVal = value \n",
    "                currAction = action \n",
    "\n",
    "            game.board = origBoard\n",
    "            game.currTurn = origTurn\n",
    "\n",
    "        return currAction \n",
    "    \n",
    "    return minimaxValueFunction                \n",
    "\n",
    "# The value agent takes a playerNum and a value function. \n",
    "agentsPlayerOne, agentsPlayerTwo = [], []\n",
    "for i in [0, 1]:\n",
    "    agentsPlayerOne.append(ValueAgent(0, netValueFunction(nets[3][i], True), 2))\n",
    "    agentsPlayerTwo.append(ValueAgent(1, netValueFunction(nets[3][i], True), 2))\n",
    "    \n",
    "for i in [2, 3]:\n",
    "    agentsPlayerOne.append(ValueAgent(0, netValueFunction(nets[3][i], False), 2))\n",
    "    agentsPlayerTwo.append(ValueAgent(1, netValueFunction(nets[3][i], False), 2))\n",
    "\n",
    "minimaxAgentPlayerOne = ValueAgent(0, getMinimaxValueFunction(None), 2)\n",
    "minimaxAgentPlayerTwo = ValueAgent(1, getMinimaxValueFunction(None), 2)\n",
    "\n",
    "DEPTH = 3\n",
    "\n",
    "minimaxDepthAgentOne = ValueAgent(0, getMinimaxValueFunction(DEPTH, None), 2)\n",
    "minimaxDepthAgentTwo = ValueAgent(1, getMinimaxValueFunction(DEPTH, None), 2)\n",
    "\n",
    "agentsMinimaxOne, agentsMinimaxTwo = [], [] \n",
    "for i in [0, 1, 2, 3]:\n",
    "    agentsMinimaxOne.append(ValueAgent(0, getMinimaxValueFunction(DEPTH, nets[3][i]), 2))\n",
    "    agentsMinimaxTwo.append(ValueAgent(1, getMinimaxValueFunction(DEPTH, nets[3][i]), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparisons of Greedy Policy to Baseline\n",
    "\n",
    "Here, we compare the greedy policy from the learned value function to an agent that plays random policies and a minimax agent (which plays perfectly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_GAMES = 10\n",
    "\n",
    "def playGames(agents, playerOne = True, type = None, otherAgent = None):\n",
    "    for agentNum, agent in enumerate(agents): \n",
    "        TODO = None \n",
    "        log = Log(3)\n",
    "        \n",
    "        if type == \"minimax\":\n",
    "            if playerOne:\n",
    "                game = StandardTicTacToe(agent, minimaxAgentPlayerTwo, log) \n",
    "            else: \n",
    "                game = StandardTicTacToe(minimaxAgentPlayerOne, agent, log) \n",
    "        elif type == \"depth-minimax\":\n",
    "            if playerOne: \n",
    "                game = StandardTicTacToe(agent, minimaxDepthAgentTwo, log)\n",
    "            else: \n",
    "                game = StandardTicTacToe(minimaxDepthAgentOne, agent, log)\n",
    "        elif type == \"value-minimax\":\n",
    "            if playerOne: \n",
    "                game = StandardTicTacToe(agent, otherAgent, log) \n",
    "            else: \n",
    "                game = StandardTicTacToe(otherAgent, agent, log)\n",
    "        else:\n",
    "            if playerOne: \n",
    "                game = StandardTicTacToe(agent, DumbAgent(1), log)\n",
    "            else: \n",
    "                game = StandardTicTacToe(DumbAgent(1), agent, log)\n",
    "    \n",
    "        ties = 0 \n",
    "        wins = 0 \n",
    "        losses = 0 \n",
    "        for i in range(NUM_GAMES): \n",
    "            gameResult = game.play()        \n",
    "            if gameResult == 0: \n",
    "                ties += 1\n",
    "            elif (gameResult == 1) and (playerOne):\n",
    "                wins += 1\n",
    "            elif (gameResult == 2) and not playerOne:\n",
    "                wins += 1\n",
    "            else: \n",
    "                losses += 1\n",
    "        \n",
    "        if playerOne:\n",
    "            print(f\"{type} {agentNum}-Player 1: W {wins} T {ties} L {losses}\")\n",
    "        else: \n",
    "            print(f\"{type} {agentNum}-Player 2: W {wins} T {ties} L {losses}\")\n",
    "\n",
    "# Play as both player 1 and player 2 against random\n",
    "playGames(agentsPlayerOne, True, \"random\")\n",
    "playGames(agentsPlayerTwo, False, \"random\")\n",
    "\n",
    "# Play as both player 1 and player 2 against minimax\n",
    "playGames(agentsPlayerOne, True, \"minimax\")\n",
    "playGames(agentsPlayerTwo, False, \"minimax\")\n",
    "\n",
    "# Play as both player 1 and player 2 against minimax with max depth \n",
    "playGames(agentsPlayerOne, True, \"depth-minimax\")\n",
    "playGames(agentsPlayerTwo, False, \"depth-minimax\")\n",
    "\n",
    "# Play as both player 1 and player 2 against minimax with max depth and value heuristic \n",
    "for agent in agentsMinimaxOne:\n",
    "    playGames(agentsPlayerOne, True, \"value-minimax\", agent)\n",
    "    \n",
    "for agent in agentsMinimaxTwo:\n",
    "    playGames(agentsPlayerTwo, False, \"value-minimax\", agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
